{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "777787cf-a76a-437d-9ac5-adc0dbbb1a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "662ee517-85e2-4bed-b1d7-b3a92a02d56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Dataset\\\\Train\\\\train_data.csv')\n",
    "X_train = data.iloc[:, :49].values\n",
    "y_train = data.iloc[:, -1].values\n",
    "X_train = X_train.reshape((X_train.shape[0], 7, 7, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d99766d4-11ac-4774-a216-973c4fa3eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.AveragePooling2D((1, 1)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b52e870-5199-4b29-a2dc-15f583e1ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Reshape((49,1), input_shape=input_shape))\n",
    "    model.add(layers.LSTM(32, activation='tanh'))\n",
    "    model.add(layers.Reshape((1, 1, 32)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "722a49d0-613b-4d21-b78d-4bbc1e378152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder(input_shape):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Encoder\n",
    "    model.add(layers.Dense(256, input_shape= input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(layers.Dense(128))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(layers.Dense(64))\n",
    "    model.add(layers.Dense(32))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    \n",
    "    model.add(layers.Dense(32))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(layers.Dense(64))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    # Output layer\n",
    "    model.add(layers.Reshape((1,1,64)))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8a5df11-4c12-4235-9047-c969a2f1b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_model(input_shape):\n",
    "    autoencoder_model = create_autoencoder(input_shape)\n",
    "    cnn_model = create_cnn(input_shape)\n",
    "    cnn_model_1 = create_cnn(input_shape)\n",
    "    cnn_model_2 = create_cnn(input_shape)\n",
    "    lstm_model = create_lstm(input_shape)\n",
    "    \n",
    "    concatenated_outputs = layers.concatenate([autoencoder_model.output, cnn_model.output, cnn_model_1.output, cnn_model_2.output, lstm_model.output])\n",
    "    flattened_outputs = layers.Flatten()(concatenated_outputs)\n",
    "    reshaped_outputs = layers.Reshape((flattened_outputs.shape[1], 1))(flattened_outputs)\n",
    "    flatten_layer = layers.Flatten(input_shape=(None, 288, 1))(reshaped_outputs)\n",
    "    dense_layer_1 = layers.Dense(256, activation='relu')(flatten_layer)\n",
    "    dense_layer_2 = layers.Dense(128, activation='relu')(dense_layer_1)\n",
    "    dropout_layer = layers.Dropout(0.5)(dense_layer_2)\n",
    "    dense_layer_3 = layers.Dense(64, activation='relu')(dropout_layer)\n",
    "    dense_layer_4 = layers.Dense(32, activation='relu')(dense_layer_3)\n",
    "    batch_norm_layer = layers.BatchNormalization()(dense_layer_4)\n",
    "    output_layer = layers.Dense(18, activation='softmax')(batch_norm_layer)\n",
    "    model_inputs = [autoencoder_model.input, cnn_model.input, cnn_model_1.input, cnn_model_2.input, lstm_model.input]\n",
    "    model_outputs = output_layer\n",
    "\n",
    "    # Create the full model\n",
    "    full_model = models.Model(inputs=model_inputs, outputs=model_outputs)\n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1feca5b-8f9a-444e-8a37-b7375511bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_training(X_train,y_train,threshold=0.90):\n",
    "    input_shape = (7,7,1)\n",
    "    full_model = create_full_model(input_shape)\n",
    "    custom_optimizer = Adam(learning_rate=0.001)\n",
    "    full_model.compile(optimizer=custom_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    iteration = 0\n",
    "    accuracy = 0.0\n",
    "    \n",
    "    X_train_iter, X_val, y_train_iter, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.1, random_state=42)\n",
    "    while accuracy < threshold:\n",
    "        # Train the model for the current iteration\n",
    "        early_stopping_loss = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, mode='min')\n",
    "        early_stopping_accuracy = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, mode='max')\n",
    "        full_model.fit([X_train_iter, X_train_iter, X_train_iter, X_train_iter, X_train_iter], y_train_iter, epochs=25, batch_size=512, validation_data=([X_val, X_val, X_val, X_val, X_val], y_val), callbacks=[early_stopping_loss, early_stopping_accuracy], verbose=1)\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        _, accuracy = full_model.evaluate([X_train_iter, X_train_iter, X_train_iter, X_train_iter, X_train_iter], y_train_iter)\n",
    "        rounded_accuracy = round(accuracy * 100, 2)\n",
    "        print(f\"Accuracy : {rounded_accuracy}%\")\n",
    "        # Save the trained sub-model\n",
    "        full_model.save(os.path.join(\"Models\\\\SubModel\", f'sub_model_{iteration}_{rounded_accuracy}.h5'))\n",
    "        \n",
    "        probabilities = full_model.predict([X_train_iter, X_train_iter, X_train_iter, X_train_iter, X_train_iter])\n",
    "        predicted_classes = np.argmax(probabilities, axis=1)\n",
    "        correct_indices = np.where(predicted_classes == y_train_iter)[0]\n",
    "        incorrect_indices = np.where(predicted_classes != y_train_iter)[0]\n",
    "        X_train_iter_misclassified = X_train_iter[incorrect_indices]\n",
    "        y_train_iter_misclassified = y_train[incorrect_indices]\n",
    "        X_train_iter, _, y_train_iter, _ = train_test_split(np.concatenate((X_train_iter[correct_indices], X_train_iter_misclassified )),np.concatenate((y_train_iter[correct_indices],y_train_iter_misclassified)), test_size=0.1, random_state=42)\n",
    "        iteration += 1\n",
    "\n",
    "    print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "771f1532-47b0-4e55-8938-cb7ccd88ce37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "238/238 [==============================] - 59s 214ms/step - loss: 1.7388 - accuracy: 0.4841 - val_loss: 1.4534 - val_accuracy: 0.5716\n",
      "Epoch 2/25\n",
      "238/238 [==============================] - 44s 186ms/step - loss: 0.9694 - accuracy: 0.6770 - val_loss: 0.9373 - val_accuracy: 0.6626\n",
      "Epoch 3/25\n",
      "238/238 [==============================] - 42s 177ms/step - loss: 0.7668 - accuracy: 0.7170 - val_loss: 0.7134 - val_accuracy: 0.7341\n",
      "Epoch 4/25\n",
      "238/238 [==============================] - 41s 173ms/step - loss: 0.7271 - accuracy: 0.7239 - val_loss: 0.7514 - val_accuracy: 0.7122\n",
      "Epoch 5/25\n",
      "238/238 [==============================] - 41s 171ms/step - loss: 0.6944 - accuracy: 0.7328 - val_loss: 0.8105 - val_accuracy: 0.6775\n",
      "Epoch 6/25\n",
      "238/238 [==============================] - 41s 174ms/step - loss: 0.6656 - accuracy: 0.7398 - val_loss: 1.0662 - val_accuracy: 0.6133\n",
      "Epoch 7/25\n",
      "238/238 [==============================] - 44s 183ms/step - loss: 0.6601 - accuracy: 0.7416 - val_loss: 0.8451 - val_accuracy: 0.7005\n",
      "Epoch 8/25\n",
      "238/238 [==============================] - 45s 189ms/step - loss: 0.6596 - accuracy: 0.7404 - val_loss: 0.6866 - val_accuracy: 0.7427\n",
      "Epoch 9/25\n",
      "238/238 [==============================] - 44s 184ms/step - loss: 0.6315 - accuracy: 0.7491 - val_loss: 0.7110 - val_accuracy: 0.7250\n",
      "Epoch 10/25\n",
      "238/238 [==============================] - 44s 186ms/step - loss: 0.6215 - accuracy: 0.7514 - val_loss: 0.9718 - val_accuracy: 0.6547\n",
      "Epoch 11/25\n",
      "238/238 [==============================] - 44s 184ms/step - loss: 0.6203 - accuracy: 0.7520 - val_loss: 0.9905 - val_accuracy: 0.6186\n",
      "Epoch 12/25\n",
      "238/238 [==============================] - 44s 184ms/step - loss: 0.6061 - accuracy: 0.7563 - val_loss: 0.9359 - val_accuracy: 0.6520\n",
      "Epoch 13/25\n",
      "238/238 [==============================] - 44s 187ms/step - loss: 0.6047 - accuracy: 0.7557 - val_loss: 0.8047 - val_accuracy: 0.6953\n",
      "3797/3797 [==============================] - 29s 8ms/step - loss: 0.6777 - accuracy: 0.7455\n",
      "Accuracy : 74.55%\n",
      "3797/3797 [==============================] - 25s 6ms/step\n",
      "Epoch 1/25\n",
      "214/214 [==============================] - 39s 182ms/step - loss: 1.0606 - accuracy: 0.7247 - val_loss: 1.1549 - val_accuracy: 0.6521\n",
      "Epoch 2/25\n",
      "214/214 [==============================] - 38s 178ms/step - loss: 0.9404 - accuracy: 0.7410 - val_loss: 1.3566 - val_accuracy: 0.5390\n",
      "Epoch 3/25\n",
      "214/214 [==============================] - 39s 181ms/step - loss: 0.9193 - accuracy: 0.7486 - val_loss: 1.2404 - val_accuracy: 0.6341\n",
      "Epoch 4/25\n",
      "214/214 [==============================] - 38s 175ms/step - loss: 0.9120 - accuracy: 0.7505 - val_loss: 1.1374 - val_accuracy: 0.6943\n",
      "Epoch 5/25\n",
      "214/214 [==============================] - 39s 181ms/step - loss: 0.9060 - accuracy: 0.7517 - val_loss: 1.2255 - val_accuracy: 0.6517\n",
      "Epoch 6/25\n",
      "214/214 [==============================] - 38s 180ms/step - loss: 0.9030 - accuracy: 0.7531 - val_loss: 1.1985 - val_accuracy: 0.6760\n",
      "Epoch 7/25\n",
      "214/214 [==============================] - 40s 187ms/step - loss: 0.8987 - accuracy: 0.7550 - val_loss: 1.2129 - val_accuracy: 0.6489\n",
      "Epoch 8/25\n",
      "214/214 [==============================] - 37s 173ms/step - loss: 0.9006 - accuracy: 0.7526 - val_loss: 1.1245 - val_accuracy: 0.7159\n",
      "Epoch 9/25\n",
      "214/214 [==============================] - 38s 180ms/step - loss: 0.8952 - accuracy: 0.7546 - val_loss: 1.2275 - val_accuracy: 0.6346\n",
      "Epoch 10/25\n",
      "214/214 [==============================] - 40s 185ms/step - loss: 0.8964 - accuracy: 0.7548 - val_loss: 1.1658 - val_accuracy: 0.6824\n",
      "Epoch 11/25\n",
      "214/214 [==============================] - 40s 185ms/step - loss: 0.8944 - accuracy: 0.7554 - val_loss: 1.1399 - val_accuracy: 0.7073\n",
      "Epoch 12/25\n",
      "214/214 [==============================] - 38s 180ms/step - loss: 0.8935 - accuracy: 0.7549 - val_loss: 1.2486 - val_accuracy: 0.6341\n",
      "Epoch 13/25\n",
      "214/214 [==============================] - 39s 181ms/step - loss: 0.8907 - accuracy: 0.7557 - val_loss: 1.2340 - val_accuracy: 0.6502\n",
      "3418/3418 [==============================] - 24s 7ms/step - loss: 0.9010 - accuracy: 0.7539\n",
      "Accuracy : 75.39%\n",
      "3418/3418 [==============================] - 23s 7ms/step\n",
      "Epoch 1/25\n",
      "193/193 [==============================] - 37s 191ms/step - loss: 0.8488 - accuracy: 0.7781 - val_loss: 1.2512 - val_accuracy: 0.6834\n",
      "Epoch 2/25\n",
      "193/193 [==============================] - 37s 194ms/step - loss: 0.8471 - accuracy: 0.7802 - val_loss: 1.3126 - val_accuracy: 0.6833\n",
      "Epoch 3/25\n",
      "193/193 [==============================] - 36s 185ms/step - loss: 0.8351 - accuracy: 0.7868 - val_loss: 1.3123 - val_accuracy: 0.6674\n",
      "Epoch 4/25\n",
      "193/193 [==============================] - 34s 175ms/step - loss: 0.8333 - accuracy: 0.7872 - val_loss: 1.4242 - val_accuracy: 0.6070\n",
      "Epoch 5/25\n",
      "193/193 [==============================] - 34s 176ms/step - loss: 0.8343 - accuracy: 0.7854 - val_loss: 1.2946 - val_accuracy: 0.6627\n",
      "Epoch 6/25\n",
      "193/193 [==============================] - 35s 182ms/step - loss: 0.8333 - accuracy: 0.7869 - val_loss: 1.3307 - val_accuracy: 0.6530\n",
      "3076/3076 [==============================] - 24s 8ms/step - loss: 0.8447 - accuracy: 0.7772\n",
      "Accuracy : 77.72%\n",
      "3076/3076 [==============================] - 23s 7ms/step\n",
      "Epoch 1/25\n",
      "173/173 [==============================] - 34s 196ms/step - loss: 0.7742 - accuracy: 0.8084 - val_loss: 1.3646 - val_accuracy: 0.6674\n",
      "Epoch 2/25\n",
      "173/173 [==============================] - 34s 194ms/step - loss: 0.7737 - accuracy: 0.8085 - val_loss: 1.3810 - val_accuracy: 0.6523\n",
      "Epoch 3/25\n",
      "173/173 [==============================] - 33s 194ms/step - loss: 0.7693 - accuracy: 0.8112 - val_loss: 1.4259 - val_accuracy: 0.6721\n",
      "Epoch 4/25\n",
      "173/173 [==============================] - 32s 185ms/step - loss: 0.7651 - accuracy: 0.8118 - val_loss: 1.4124 - val_accuracy: 0.6350\n",
      "Epoch 5/25\n",
      "173/173 [==============================] - 33s 189ms/step - loss: 0.7633 - accuracy: 0.8119 - val_loss: 1.4492 - val_accuracy: 0.6417\n",
      "Epoch 6/25\n",
      "173/173 [==============================] - 32s 185ms/step - loss: 0.7595 - accuracy: 0.8130 - val_loss: 1.3989 - val_accuracy: 0.6373\n",
      "2768/2768 [==============================] - 20s 7ms/step - loss: 0.7932 - accuracy: 0.8039\n",
      "Accuracy : 80.39%\n",
      "2768/2768 [==============================] - 18s 6ms/step\n",
      "Epoch 1/25\n",
      "156/156 [==============================] - 27s 175ms/step - loss: 0.6977 - accuracy: 0.8351 - val_loss: 1.5442 - val_accuracy: 0.6535\n",
      "Epoch 2/25\n",
      "156/156 [==============================] - 41s 261ms/step - loss: 0.6952 - accuracy: 0.8355 - val_loss: 1.5541 - val_accuracy: 0.6418\n",
      "Epoch 3/25\n",
      "156/156 [==============================] - 35s 224ms/step - loss: 0.6870 - accuracy: 0.8384 - val_loss: 1.6161 - val_accuracy: 0.6407\n",
      "Epoch 4/25\n",
      "156/156 [==============================] - 28s 181ms/step - loss: 0.6855 - accuracy: 0.8386 - val_loss: 1.6156 - val_accuracy: 0.6107\n",
      "Epoch 5/25\n",
      "156/156 [==============================] - 33s 210ms/step - loss: 0.6872 - accuracy: 0.8381 - val_loss: 1.5195 - val_accuracy: 0.6596\n",
      "Epoch 6/25\n",
      "156/156 [==============================] - 32s 207ms/step - loss: 0.6956 - accuracy: 0.8338 - val_loss: 1.6673 - val_accuracy: 0.6071\n",
      "Epoch 7/25\n",
      "156/156 [==============================] - 30s 191ms/step - loss: 0.6842 - accuracy: 0.8394 - val_loss: 1.6125 - val_accuracy: 0.5937\n",
      "Epoch 8/25\n",
      "156/156 [==============================] - 29s 185ms/step - loss: 0.6847 - accuracy: 0.8382 - val_loss: 1.8626 - val_accuracy: 0.5676\n",
      "Epoch 9/25\n",
      "156/156 [==============================] - 28s 177ms/step - loss: 0.6827 - accuracy: 0.8394 - val_loss: 1.6187 - val_accuracy: 0.6058\n",
      "Epoch 10/25\n",
      "156/156 [==============================] - 28s 180ms/step - loss: 0.6799 - accuracy: 0.8405 - val_loss: 1.6542 - val_accuracy: 0.6060\n",
      "2491/2491 [==============================] - 16s 7ms/step - loss: 0.7016 - accuracy: 0.8379\n",
      "Accuracy : 83.79%\n",
      "2491/2491 [==============================] - 16s 6ms/step\n",
      "Epoch 1/25\n",
      "141/141 [==============================] - 25s 175ms/step - loss: 0.6232 - accuracy: 0.8534 - val_loss: 1.8642 - val_accuracy: 0.5622\n",
      "Epoch 2/25\n",
      "141/141 [==============================] - 28s 197ms/step - loss: 0.6044 - accuracy: 0.8636 - val_loss: 1.6516 - val_accuracy: 0.6384\n",
      "Epoch 3/25\n",
      "141/141 [==============================] - 27s 195ms/step - loss: 0.5970 - accuracy: 0.8659 - val_loss: 1.6245 - val_accuracy: 0.6453\n",
      "Epoch 4/25\n",
      "141/141 [==============================] - 27s 190ms/step - loss: 0.5969 - accuracy: 0.8657 - val_loss: 1.5984 - val_accuracy: 0.6553\n",
      "Epoch 5/25\n",
      "141/141 [==============================] - 28s 197ms/step - loss: 0.6012 - accuracy: 0.8643 - val_loss: 1.8415 - val_accuracy: 0.5586\n",
      "Epoch 6/25\n",
      "141/141 [==============================] - 31s 223ms/step - loss: 0.6051 - accuracy: 0.8619 - val_loss: 1.6786 - val_accuracy: 0.6227\n",
      "Epoch 7/25\n",
      "141/141 [==============================] - 26s 182ms/step - loss: 0.5964 - accuracy: 0.8658 - val_loss: 1.6546 - val_accuracy: 0.6321\n",
      "Epoch 8/25\n",
      "141/141 [==============================] - 26s 182ms/step - loss: 0.5947 - accuracy: 0.8670 - val_loss: 1.7866 - val_accuracy: 0.5641\n",
      "Epoch 9/25\n",
      "141/141 [==============================] - 26s 185ms/step - loss: 0.5920 - accuracy: 0.8672 - val_loss: 1.9593 - val_accuracy: 0.5580\n",
      "2242/2242 [==============================] - 17s 7ms/step - loss: 0.6150 - accuracy: 0.8652\n",
      "Accuracy : 86.52%\n",
      "2242/2242 [==============================] - 15s 7ms/step\n",
      "Epoch 1/25\n",
      "127/127 [==============================] - 24s 192ms/step - loss: 0.5284 - accuracy: 0.8815 - val_loss: 1.7461 - val_accuracy: 0.6371\n",
      "Epoch 2/25\n",
      "127/127 [==============================] - 28s 221ms/step - loss: 0.5228 - accuracy: 0.8827 - val_loss: 1.7207 - val_accuracy: 0.6549\n",
      "Epoch 3/25\n",
      "127/127 [==============================] - 25s 194ms/step - loss: 0.5588 - accuracy: 0.8707 - val_loss: 2.0269 - val_accuracy: 0.5662\n",
      "Epoch 4/25\n",
      "127/127 [==============================] - 23s 180ms/step - loss: 0.5273 - accuracy: 0.8820 - val_loss: 1.9702 - val_accuracy: 0.5892\n",
      "Epoch 5/25\n",
      "127/127 [==============================] - 29s 229ms/step - loss: 0.5293 - accuracy: 0.8801 - val_loss: 2.0338 - val_accuracy: 0.5241\n",
      "Epoch 6/25\n",
      "127/127 [==============================] - 23s 180ms/step - loss: 0.5222 - accuracy: 0.8823 - val_loss: 1.9330 - val_accuracy: 0.5534\n",
      "Epoch 7/25\n",
      "127/127 [==============================] - 23s 178ms/step - loss: 0.5215 - accuracy: 0.8832 - val_loss: 1.8599 - val_accuracy: 0.6010\n",
      "2018/2018 [==============================] - 16s 8ms/step - loss: 0.5330 - accuracy: 0.8851\n",
      "Accuracy : 88.51%\n",
      "2018/2018 [==============================] - 15s 7ms/step\n",
      "Epoch 1/25\n",
      "114/114 [==============================] - 21s 185ms/step - loss: 0.4686 - accuracy: 0.8945 - val_loss: 2.0130 - val_accuracy: 0.6168\n",
      "Epoch 2/25\n",
      "114/114 [==============================] - 26s 231ms/step - loss: 0.4668 - accuracy: 0.8954 - val_loss: 1.9236 - val_accuracy: 0.6048\n",
      "Epoch 3/25\n",
      "114/114 [==============================] - 23s 206ms/step - loss: 0.4609 - accuracy: 0.8971 - val_loss: 1.9357 - val_accuracy: 0.6068\n",
      "Epoch 4/25\n",
      "114/114 [==============================] - 23s 204ms/step - loss: 0.4677 - accuracy: 0.8944 - val_loss: 2.0729 - val_accuracy: 0.5437\n",
      "Epoch 5/25\n",
      "114/114 [==============================] - 21s 185ms/step - loss: 0.4545 - accuracy: 0.8991 - val_loss: 2.3872 - val_accuracy: 0.5275\n",
      "Epoch 6/25\n",
      "114/114 [==============================] - 21s 181ms/step - loss: 0.4603 - accuracy: 0.8969 - val_loss: 2.3384 - val_accuracy: 0.5364\n",
      "1816/1816 [==============================] - 13s 7ms/step - loss: 0.5925 - accuracy: 0.8617\n",
      "Accuracy : 86.17%\n",
      "1816/1816 [==============================] - 12s 7ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 19s 186ms/step - loss: 0.4856 - accuracy: 0.8890 - val_loss: 2.1529 - val_accuracy: 0.5921\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 19s 189ms/step - loss: 0.4812 - accuracy: 0.8905 - val_loss: 2.2094 - val_accuracy: 0.5899\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.4791 - accuracy: 0.8910 - val_loss: 2.1856 - val_accuracy: 0.5910\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 21s 208ms/step - loss: 0.4785 - accuracy: 0.8911 - val_loss: 2.1532 - val_accuracy: 0.6013\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 21s 205ms/step - loss: 0.4758 - accuracy: 0.8921 - val_loss: 2.1340 - val_accuracy: 0.5813\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 22s 215ms/step - loss: 0.4807 - accuracy: 0.8897 - val_loss: 2.0793 - val_accuracy: 0.5884\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 18s 172ms/step - loss: 0.4763 - accuracy: 0.8917 - val_loss: 2.1352 - val_accuracy: 0.5877\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 18s 173ms/step - loss: 0.4781 - accuracy: 0.8913 - val_loss: 2.0671 - val_accuracy: 0.6155\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 18s 174ms/step - loss: 0.4973 - accuracy: 0.8856 - val_loss: 2.3011 - val_accuracy: 0.5719\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 18s 173ms/step - loss: 0.4778 - accuracy: 0.8910 - val_loss: 2.2739 - val_accuracy: 0.5855\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 18s 171ms/step - loss: 0.4735 - accuracy: 0.8919 - val_loss: 2.3358 - val_accuracy: 0.5740\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 18s 170ms/step - loss: 0.4710 - accuracy: 0.8924 - val_loss: 2.3111 - val_accuracy: 0.5854\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 18s 171ms/step - loss: 0.4723 - accuracy: 0.8925 - val_loss: 2.2492 - val_accuracy: 0.5810\n",
      "1635/1635 [==============================] - 10s 6ms/step - loss: 0.4904 - accuracy: 0.8938\n",
      "Accuracy : 89.38%\n",
      "1635/1635 [==============================] - 10s 6ms/step\n",
      "Epoch 1/25\n",
      "92/92 [==============================] - 16s 177ms/step - loss: 0.4028 - accuracy: 0.9123 - val_loss: 2.5444 - val_accuracy: 0.5419\n",
      "Epoch 2/25\n",
      "92/92 [==============================] - 16s 177ms/step - loss: 0.4002 - accuracy: 0.9124 - val_loss: 2.4344 - val_accuracy: 0.5646\n",
      "Epoch 3/25\n",
      "92/92 [==============================] - 16s 177ms/step - loss: 0.4006 - accuracy: 0.9122 - val_loss: 2.3631 - val_accuracy: 0.5369\n",
      "Epoch 4/25\n",
      "92/92 [==============================] - 16s 177ms/step - loss: 0.4053 - accuracy: 0.9115 - val_loss: 2.3105 - val_accuracy: 0.5642\n",
      "Epoch 5/25\n",
      "92/92 [==============================] - 16s 177ms/step - loss: 0.4003 - accuracy: 0.9124 - val_loss: 2.4213 - val_accuracy: 0.5678\n",
      "Epoch 6/25\n",
      "92/92 [==============================] - 17s 181ms/step - loss: 0.3993 - accuracy: 0.9134 - val_loss: 2.3924 - val_accuracy: 0.5646\n",
      "Epoch 7/25\n",
      "92/92 [==============================] - 18s 199ms/step - loss: 0.4251 - accuracy: 0.9031 - val_loss: 2.5545 - val_accuracy: 0.5629\n",
      "Epoch 8/25\n",
      "92/92 [==============================] - 16s 179ms/step - loss: 0.3988 - accuracy: 0.9136 - val_loss: 2.6877 - val_accuracy: 0.5610\n",
      "Epoch 9/25\n",
      "92/92 [==============================] - 16s 179ms/step - loss: 0.3999 - accuracy: 0.9130 - val_loss: 2.6905 - val_accuracy: 0.5386\n",
      "1471/1471 [==============================] - 10s 7ms/step - loss: 0.5154 - accuracy: 0.8598\n",
      "Accuracy : 85.98%\n",
      "1471/1471 [==============================] - 14s 10ms/step\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 16s 187ms/step - loss: 0.4680 - accuracy: 0.8970 - val_loss: 2.3548 - val_accuracy: 0.5613\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 15s 181ms/step - loss: 0.4436 - accuracy: 0.9014 - val_loss: 2.5984 - val_accuracy: 0.5584\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 15s 184ms/step - loss: 0.4414 - accuracy: 0.9020 - val_loss: 2.3659 - val_accuracy: 0.5628\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 15s 181ms/step - loss: 0.4409 - accuracy: 0.9022 - val_loss: 2.5077 - val_accuracy: 0.5608\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 15s 184ms/step - loss: 0.4495 - accuracy: 0.8985 - val_loss: 2.4096 - val_accuracy: 0.5568\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 15s 181ms/step - loss: 0.4378 - accuracy: 0.9019 - val_loss: 2.4274 - val_accuracy: 0.5649\n",
      "1324/1324 [==============================] - 9s 7ms/step - loss: 0.4763 - accuracy: 0.8997\n",
      "Accuracy : 89.97%\n",
      "1324/1324 [==============================] - 8s 6ms/step\n",
      "Epoch 1/25\n",
      "75/75 [==============================] - 14s 185ms/step - loss: 0.3603 - accuracy: 0.9258 - val_loss: 2.6994 - val_accuracy: 0.5616\n",
      "Epoch 2/25\n",
      "75/75 [==============================] - 14s 185ms/step - loss: 0.3566 - accuracy: 0.9265 - val_loss: 2.7006 - val_accuracy: 0.5571\n",
      "Epoch 3/25\n",
      "75/75 [==============================] - 16s 208ms/step - loss: 0.3536 - accuracy: 0.9271 - val_loss: 2.7615 - val_accuracy: 0.5580\n",
      "Epoch 4/25\n",
      "75/75 [==============================] - 17s 232ms/step - loss: 0.4102 - accuracy: 0.9080 - val_loss: 2.6637 - val_accuracy: 0.5621\n",
      "Epoch 5/25\n",
      "75/75 [==============================] - 14s 191ms/step - loss: 0.3650 - accuracy: 0.9247 - val_loss: 2.6342 - val_accuracy: 0.5398\n",
      "Epoch 6/25\n",
      "75/75 [==============================] - 14s 187ms/step - loss: 0.3596 - accuracy: 0.9261 - val_loss: 2.7378 - val_accuracy: 0.5568\n",
      "Epoch 7/25\n",
      "75/75 [==============================] - 14s 186ms/step - loss: 0.3540 - accuracy: 0.9270 - val_loss: 2.8445 - val_accuracy: 0.5565\n",
      "Epoch 8/25\n",
      "75/75 [==============================] - 14s 187ms/step - loss: 0.3538 - accuracy: 0.9270 - val_loss: 2.7753 - val_accuracy: 0.5590\n",
      "Epoch 9/25\n",
      "75/75 [==============================] - 14s 188ms/step - loss: 0.3521 - accuracy: 0.9272 - val_loss: 2.6415 - val_accuracy: 0.5556\n",
      "1192/1192 [==============================] - 8s 7ms/step - loss: 0.4215 - accuracy: 0.9091\n",
      "Accuracy : 90.91%\n",
      "1192/1192 [==============================] - 8s 7ms/step\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "iterative_training(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
