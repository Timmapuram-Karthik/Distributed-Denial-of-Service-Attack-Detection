{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d31a5805-72c5-4a4b-a17f-3185a552eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9626d46b-52c5-4415-962d-1174ac9f05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2numeric_hash(text):\n",
    "    import hashlib\n",
    "    return int(hashlib.md5(text).hexdigest()[:8], 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae406079-4e76-4443-8da5-bb98e309d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(data):\n",
    "    # Flows Packet/s e Bytes/s - Replace infinity by 0\n",
    "    data = data.replace('Infinity','0')\n",
    "    data = data.replace(np.inf,0)\n",
    "    #samples = samples.replace('nan','0')\n",
    "    data[' Flow Packets/s'] = pd.to_numeric(data[' Flow Packets/s'])\n",
    "    \n",
    "    data['Flow Bytes/s'] = data['Flow Bytes/s'].fillna(0)\n",
    "    data['Flow Bytes/s'] = pd.to_numeric(data['Flow Bytes/s'])\n",
    "    \n",
    "    \n",
    "    #Label\n",
    "    # Create a label encoder object\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    # Fit the label encoder to the label column and transform the labels\n",
    "    data[' Label'] = label_encoder.fit_transform(data[' Label'])\n",
    "    \n",
    "    # Get the mapping between original labels and encoded values\n",
    "    label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e0436d4-ff21-4715-ab17-b72a00f8fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(data):\n",
    "    X = data.iloc[:,0:(data.shape[1]-1)]\n",
    "    y = data.iloc[:,-1]\n",
    "    # Initialize a random forest classifier \n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Fit the classifier to the entire dataset to get feature importances\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    feature_importances = clf.feature_importances_\n",
    "    importance_dict = dict(zip(data.columns, feature_importances))\n",
    "    sorted_importance_dict = dict(sorted(importance_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    top_50_features = dict(list(sorted_importance_dict.items())[:50])\n",
    "    data_important = data[list(top_50_features.keys())]\n",
    "    data_important[' Label'] = data[' Label']\n",
    "    return data_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee816a5a-1d30-4425-9635-4004304ee15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing():\n",
    "    data = pd.read_csv(\"Dataset\\\\CIC_DDoS.csv\")\n",
    "    cols = [' Source IP',' Destination IP','Flow ID','SimillarHTTP','Unnamed: 0',' Source Port',' Timestamp',' Inbound']\n",
    "    data = data.drop(columns=cols)\n",
    "    data = data_cleaning(data)\n",
    "    data_important = feature_selection(data)\n",
    "    return data_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5371917-6469-4d96-8354-81c1d50d63d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d7a409b-5bc9-4991-9d7a-01690d22431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :49]\n",
    "y = data.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f34048ab-80a7-4f79-96d0-30e0f495c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "train_data.to_csv('Dataset\\\\Train\\\\train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8874c2d8-b4f0-42c9-9d45-48cdb9799175",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "test_data.to_csv('Dataset\\\\Test\\\\test_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
